# üöÄ Complete DevOps Project - Production Ready

A comprehensive, production-ready DevOps project implementing GitOps, observability, advanced deployment strategies, service mesh, cost optimization, and load testing.

## üìã Table of Contents

- [Architecture Overview](#architecture-overview)
- [Features](#features)
- [Prerequisites](#prerequisites)
- [Quick Start](#quick-start)
- [Project Structure](#project-structure)
- [Component Details](#component-details)
- [Deployment Strategies](#deployment-strategies)
- [Monitoring & Observability](#monitoring--observability)
- [Cost Optimization](#cost-optimization)
- [Service Mesh](#service-mesh)
- [Load Testing](#load-testing)
- [Notifications](#notifications)
- [Security](#security)
- [Troubleshooting](#troubleshooting)
- [Best Practices](#best-practices)

## üèóÔ∏è Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        GitHub Actions                        ‚îÇ
‚îÇ  (CI/CD Pipeline, Security Scanning, Notifications)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Kubernetes Cluster                        ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                     ArgoCD                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (GitOps Controller - Automated Deployments)         ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                  Argo Rollouts                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (Canary/Blue-Green Deployments)                     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ             Service Mesh (Istio/Linkerd)             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (Traffic Management, Security, Observability)       ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ          Monitoring Stack                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Prometheus ‚îÇ Grafana ‚îÇ Alertmanager ‚îÇ Jaeger        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ          Cost Optimization                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Cluster Autoscaler ‚îÇ VPA ‚îÇ Karpenter ‚îÇ Kubecost    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## ‚ú® Features

### Core Features
- ‚úÖ **GitOps Workflow** - ArgoCD for declarative deployments
- ‚úÖ **CI/CD Pipeline** - GitHub Actions with automated testing
- ‚úÖ **Container Registry** - GitHub Container Registry integration
- ‚úÖ **Multi-Environment** - Dev, Staging, Production

### Deployment Strategies
- ‚úÖ **Canary Deployments** - Progressive traffic shifting
- ‚úÖ **Blue-Green Deployments** - Zero-downtime releases
- ‚úÖ **Automated Rollbacks** - Based on Prometheus metrics
- ‚úÖ **Manual Approval Gates** - For production deployments

### Monitoring & Observability
- ‚úÖ **Metrics Collection** - Prometheus with custom metrics
- ‚úÖ **Visualization** - Grafana dashboards
- ‚úÖ **Distributed Tracing** - Jaeger integration
- ‚úÖ **Log Aggregation** - ELK/Loki stack ready
- ‚úÖ **Alerting** - Alertmanager with multiple channels

### Service Mesh
- ‚úÖ **Traffic Management** - Intelligent routing, load balancing
- ‚úÖ **Security** - mTLS, authorization policies
- ‚úÖ **Resilience** - Circuit breakers, retries, timeouts
- ‚úÖ **Observability** - Service-to-service metrics

### Cost Optimization
- ‚úÖ **Cluster Autoscaler** - Automatic node scaling
- ‚úÖ **VPA** - Right-sizing pod resources
- ‚úÖ **Karpenter** - Advanced autoscaling with spot instances
- ‚úÖ **Resource Quotas** - Namespace-level limits
- ‚úÖ **Cost Monitoring** - Kubecost integration
- ‚úÖ **Descheduler** - Workload optimization

### Notifications
- ‚úÖ **Slack Integration** - Deployment and alert notifications
- ‚úÖ **Discord Integration** - Alternative notification channel
- ‚úÖ **Email Alerts** - Critical alerts via email
- ‚úÖ **PagerDuty** - Incident management integration

### Security
- ‚úÖ **Container Scanning** - Trivy for vulnerabilities
- ‚úÖ **Secret Management** - Sealed Secrets
- ‚úÖ **RBAC** - Role-based access control
- ‚úÖ **Network Policies** - Pod-to-pod communication control
- ‚úÖ **Pod Security Standards** - Restricted profiles

### Load Testing
- ‚úÖ **K6 Integration** - Modern load testing
- ‚úÖ **Multiple Test Types** - Stress, spike, soak tests
- ‚úÖ **Automated Testing** - Via GitHub Actions
- ‚úÖ **Metrics Collection** - InfluxDB + Grafana

## üì¶ Prerequisites

- **Kubernetes Cluster** (1.24+)
  - EKS, GKE, AKS, or local (kind, k3s, minikube)
  - Minimum 3 nodes (2 CPU, 4GB RAM each)
- **kubectl** (configured)
- **Helm** 3+
- **Docker** (for building images)
- **Git**

## üöÄ Quick Start

### 1. Install Tools

```bash
./scripts/install-tools.sh
```

This installs:
- kubectl
- Helm
- ArgoCD CLI
- Argo Rollouts plugin
- k9s
- Trivy
- kubeval
- kustomize
- kubeseal

### 2. Setup Cluster

```bash
./scripts/setup-cluster.sh
```

This installs:
- ArgoCD
- Argo Rollouts
- Prometheus Stack
- Ingress NGINX
- Cert Manager
- Sealed Secrets

### 3. Configure Secrets

```bash
# GitHub Container Registry
kubectl create secret docker-registry ghcr-secret \
  --docker-server=ghcr.io \
  --docker-username=YOUR_USERNAME \
  --docker-password=YOUR_TOKEN \
  -n production

# Slack/Discord Webhooks
kubectl create secret generic notification-secrets \
  --from-literal=slack-webhook-url=YOUR_SLACK_WEBHOOK \
  --from-literal=discord-webhook-url=YOUR_DISCORD_WEBHOOK \
  -n argocd
```

### 4. Deploy Application

```bash
# Build and push image
docker build -t ghcr.io/your-org/sample-app:latest ./apps/sample-app
docker push ghcr.io/your-org/sample-app:latest

# Deploy to production
kubectl apply -f argocd/applications/sample-app-prod.yml

# Access dashboards
kubectl port-forward svc/argocd-server -n argocd 8080:443
kubectl port-forward svc/prometheus-grafana -n monitoring 3000:80
```

## üìÅ Project Structure

```
ArgoStack/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/               # GitHub Actions
‚îÇ       ‚îú‚îÄ‚îÄ ci.yml
‚îÇ       ‚îú‚îÄ‚îÄ security-scan.yml
‚îÇ       ‚îú‚îÄ‚îÄ release.yml
‚îÇ       ‚îî‚îÄ‚îÄ load-test.yml
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îî‚îÄ‚îÄ sample-app/              # Application code
‚îÇ       ‚îú‚îÄ‚îÄ src/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ app.py
‚îÇ       ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ       ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ       ‚îî‚îÄ‚îÄ .dockerignore
‚îú‚îÄ‚îÄ k8s/
‚îÇ   ‚îú‚îÄ‚îÄ base/                    # Base Kubernetes manifests
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deployment.yml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ service.yml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ servicemonitor.yml
‚îÇ   ‚îî‚îÄ‚îÄ overlays/                # Environment-specific
‚îÇ       ‚îú‚îÄ‚îÄ dev/
‚îÇ       ‚îú‚îÄ‚îÄ staging/
‚îÇ       ‚îî‚îÄ‚îÄ prod/
‚îú‚îÄ‚îÄ argocd/
‚îÇ   ‚îú‚îÄ‚îÄ applications/            # ArgoCD apps
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sample-app-dev.yml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sample-app-staging.yml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sample-app-prod.yml
‚îÇ   ‚îú‚îÄ‚îÄ projects/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ project.yml
‚îÇ   ‚îî‚îÄ‚îÄ notifications/
‚îÇ       ‚îú‚îÄ‚îÄ argocd-notifications-cm.yaml
‚îÇ       ‚îî‚îÄ‚îÄ argocd-notifications-secret.yaml
‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îú‚îÄ‚îÄ prometheus/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prometheus-config.yml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ alerting-rules.yml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ advanced-alerting-rules.yml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cost-alerts.yaml
‚îÇ   ‚îî‚îÄ‚îÄ grafana/
‚îÇ       ‚îú‚îÄ‚îÄ dashboards/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ app-dashboard.json
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ istio-dashboard.json
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ k6-dashboard.json
‚îÇ       ‚îî‚îÄ‚îÄ grafana-config.yml
‚îú‚îÄ‚îÄ service-mesh/
‚îÇ   ‚îú‚îÄ‚îÄ istio/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ install.sh
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gateway.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ virtual-service.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ destination-rule.yaml
‚îÇ   ‚îî‚îÄ‚îÄ linkerd/
‚îÇ       ‚îú‚îÄ‚îÄ install.sh
‚îÇ       ‚îî‚îÄ‚îÄ service-profile.yaml
‚îú‚îÄ‚îÄ autoscaling/
‚îÇ   ‚îú‚îÄ‚îÄ cluster-autoscaler/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rbac.yaml
‚îÇ   ‚îú‚îÄ‚îÄ vpa/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sample-app-vpa.yaml
‚îÇ   ‚îú‚îÄ‚îÄ karpenter/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ provisioner.yaml
‚îÇ   ‚îú‚îÄ‚îÄ priority-classes.yaml
‚îÇ   ‚îú‚îÄ‚îÄ resource-quotas/
‚îÇ   ‚îî‚îÄ‚îÄ descheduler/
‚îú‚îÄ‚îÄ load-testing/
‚îÇ   ‚îú‚îÄ‚îÄ k6/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ basic-load-test.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stress-test.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ spike-test.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ soak-test.js
‚îÇ   ‚îú‚îÄ‚îÄ artillery/
‚îÇ   ‚îî‚îÄ‚îÄ locust/
‚îú‚îÄ‚îÄ helm-charts/
‚îÇ   ‚îî‚îÄ‚îÄ sample-app/
‚îÇ       ‚îú‚îÄ‚îÄ Chart.yaml
‚îÇ       ‚îú‚îÄ‚îÄ values.yaml
‚îÇ       ‚îî‚îÄ‚îÄ templates/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ install-tools.sh
‚îÇ   ‚îú‚îÄ‚îÄ setup-cluster.sh
‚îÇ   ‚îú‚îÄ‚îÄ backup-etcd.sh
‚îÇ   ‚îî‚îÄ‚îÄ generate-docs.sh
‚îî‚îÄ‚îÄ docs/
    ‚îî‚îÄ‚îÄ complete-documentation.md
```

## üéØ Component Details

### ArgoCD

Access ArgoCD UI:
```bash
kubectl port-forward svc/argocd-server -n argocd 8080:443
# URL: https://localhost:8080
# Username: admin
# Password: [shown in output]
```

Sync applications:
```bash
argocd app sync sample-app-prod
argocd app sync --all
```

### Prometheus

Access Prometheus:
```bash
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090
# URL: http://localhost:9090
```

Query metrics:
```promql
# Request rate
rate(http_requests_total[5m])

# Error rate
sum(rate(http_requests_total{status=~"5.."}[5m])) / sum(rate(http_requests_total[5m]))

# P95 latency
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))
```

### Grafana

Access Grafana:
```bash
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
# URL: http://localhost:3000
# Username: admin
# Password: admin123
```

Import dashboards:
- Application Metrics
- Istio Service Mesh
- K6 Load Testing
- Cost Analysis

## üé® Deployment Strategies

### Canary Deployment

```bash
# Deploy with canary
kubectl apply -f argocd/applications/sample-app-prod-with-notifications.yaml

# Watch progress
kubectl argo rollouts get rollout sample-app -n production

# Promote canary
kubectl argo rollouts promote sample-app -n production

# Abort rollout
kubectl argo rollouts abort sample-app -n production
```

Traffic split progression:
1. 20% canary, 80% stable (2 min)
2. 40% canary, 60% stable (2 min)
3. 60% canary, 40% stable (2 min)
4. 80% canary, 20% stable (2 min)
5. 100% canary (manual promotion)

### Blue-Green Deployment

```bash
# Deploy blue-green (requires additional configuration)
kubectl apply -f k8s/rollouts/bluegreen/rollout.yaml

# Preview new version
kubectl port-forward svc/sample-app-preview -n production 8081:80

# Promote to production
kubectl argo rollouts promote sample-app-bluegreen -n production
```

## üìä Monitoring & Observability

### Custom Metrics

The application exposes the following metrics:

```
# HTTP Metrics
http_requests_total               - Total HTTP requests
http_request_duration_seconds     - Request duration histogram
http_requests_active              - Active requests gauge

# Business Metrics
business_operations_total         - Business operations counter
app_info                          - Application information
```

### Alerting Rules

**Critical Alerts:**
- SLO Violation (99.9% availability)
- High Error Rate (>5%)
- Pod Crash Looping
- Certificate Expiring Soon

**Warning Alerts:**
- High Memory Usage (>90%)
- High CPU Throttling
- Deployment Replica Mismatch
- PV Filling Up

### Distributed Tracing

View traces in Jaeger:
```bash
kubectl port-forward -n monitoring svc/jaeger-query 16686:16686
# URL: http://localhost:16686
```

## üí∞ Cost Optimization

### Cluster Autoscaler

Automatically scales nodes based on pending pods:

```yaml
# Configuration
--scale-down-enabled=true
--scale-down-delay-after-add=10m
--scale-down-unneeded-time=10m
--scale-down-utilization-threshold=0.5
```

### Vertical Pod Autoscaler (VPA)

Automatically adjusts pod resources:

```bash
# Apply VPA
kubectl apply -f autoscaling/vpa/sample-app-vpa.yaml

# Check recommendations
kubectl get vpa sample-app-vpa -o yaml
```

### Karpenter (Alternative)

Advanced autoscaling with spot instances:

```bash
# Install Karpenter (requires additional setup)
helm upgrade --install karpenter karpenter/karpenter \
  --namespace karpenter \
  --create-namespace \
  --set serviceAccount.annotations."eks\.amazonaws\.com/role-arn"=${KARPENTER_IAM_ROLE_ARN} \
  --set settings.aws.clusterName=${CLUSTER_NAME} \
  --set settings.aws.defaultInstanceProfile=KarpenterNodeInstanceProfile \
  --wait
```

### Resource Quotas

Limit resource consumption per namespace:

```bash
# Apply quotas
kubectl apply -f autoscaling/resource-quotas/production-quota.yaml
kubectl apply -f autoscaling/limit-ranges/production-limits.yaml
```

## üîó Service Mesh

### Istio Integration

Install Istio:
```bash
# Install Istio
curl -L https://istio.io/downloadIstio | sh -
cd istio-*
kubectl apply -f manifests/charts/istio-crds/files/
kubectl apply -f manifests/charts/istio-control/istio-discovery/files/
```

Deploy with Istio sidecar:
```bash
# Enable Istio injection
kubectl label namespace production istio-injection=enabled

# Deploy application
kubectl apply -f k8s/overlays/prod/
```

### Traffic Management

Configure traffic routing:
```bash
# Apply virtual service
kubectl apply -f service-mesh/istio/virtual-service.yaml

# Apply destination rules
kubectl apply -f service-mesh/istio/destination-rule.yaml
```

## üß™ Load Testing

### K6 Load Testing

Run load tests locally:
```bash
# Install k6
npm install -g k6

# Run basic load test
k6 run load-testing/k6/basic-load-test.js

# Run with environment variables
BASE_URL=http://localhost:8080 k6 run load-testing/k6/basic-load-test.js
```

Run load tests in Kubernetes:
```bash
# Create testing namespace
kubectl create namespace testing

# Create ConfigMap with test scripts
kubectl create configmap k6-scripts \
  --from-file=load-testing/k6/basic-load-test.js \
  -n testing

# Apply the job
kubectl apply -f load-testing/k8s/k6-job.yaml

# Check job status
kubectl get jobs -n testing

# View logs
kubectl logs -n testing -l app=k6
```

### GitHub Actions Load Testing

Trigger load tests via GitHub Actions:
1. Go to GitHub repository
2. Navigate to Actions tab
3. Select "Load Testing" workflow
4. Run workflow with desired parameters

## üîî Notifications

### ArgoCD Notifications

Configure notification channels:
```bash
# Apply notification configuration
kubectl apply -f argocd/notifications/argocd-notifications-cm.yaml
kubectl apply -f argocd/notifications/argocd-notifications-secret.yaml
```

Subscribe to notifications:
```yaml
# In application manifest
metadata:
  annotations:
    notifications.argoproj.io/subscribe.on-deployed.slack: "deployments"
    notifications.argoproj.io/subscribe.on-health-degraded.slack: "alerts"
```

### Alertmanager Configuration

Configure alert routing:
```bash
# Apply Alertmanager config
kubectl apply -f monitoring/alertmanager/alertmanager-config.yaml
```

## üîê Security

### Container Scanning

Scan images for vulnerabilities:
```bash
# Install Trivy
curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin

# Scan image
trivy image ghcr.io/your-org/sample-app:latest
```

### Secret Management

Securely manage secrets:
```bash
# Install kubeseal
wget https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.24.0/kubeseal-0.24.0-linux-amd64.tar.gz
tar -xvzf kubeseal-0.24.0-linux-amd64.tar.gz kubeseal
sudo install -m 755 kubeseal /usr/local/bin/kubeseal

# Create sealed secret
kubectl create secret generic my-secret \
  --from-literal=username=myuser \
  --from-literal=password=mypassword \
  -o json --dry-run=client \
  | kubeseal \
  | kubectl apply -f -
```

### Network Policies

Restrict pod communication:
```bash
# Apply network policies
kubectl apply -f k8s/network-policies/
```

## üõ†Ô∏è Troubleshooting

### Common Issues

1. **ArgoCD Sync Issues**
   ```bash
   # Check application status
   argocd app get sample-app-prod
   
   # Force sync
   argocd app sync sample-app-prod --force
   ```

2. **Pod Crash Looping**
   ```bash
   # Check pod logs
   kubectl logs -n production sample-app-xyz --previous
   
   # Describe pod
   kubectl describe pod -n production sample-app-xyz
   ```

3. **High Memory Usage**
   ```bash
   # Check VPA recommendations
   kubectl get vpa sample-app-vpa -o yaml
   
   # Check resource usage
   kubectl top pods -n production
   ```

4. **Prometheus Alerts Firing**
   ```bash
   # Check alert status
   kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090
   
   # Query active alerts
   curl http://localhost:9090/api/v1/alerts
   ```

### Debugging Commands

```bash
# Check all pods
kubectl get pods -A

# Check events
kubectl get events -A --sort-by='.lastTimestamp'

# Check logs
kubectl logs -n production deployment/sample-app

# Check resources
kubectl top nodes
kubectl top pods -n production

# Check HPA status
kubectl get hpa -n production

# Check VPA recommendations
kubectl get vpa -n production
```

## üìö Best Practices

### GitOps Best Practices

1. **Separate Configuration from Code**
   - Keep Kubernetes manifests in separate repository
   - Use Kustomize for environment-specific configurations

2. **Use Semantic Versioning**
   - Tag releases with semantic versioning
   - Use tags in ArgoCD applications

3. **Implement Proper RBAC**
   - Define least-privilege roles
   - Use ArgoCD projects for isolation

### Kubernetes Best Practices

1. **Resource Management**
   - Set resource requests and limits
   - Use VPA for optimization
   - Implement resource quotas

2. **Health Checks**
   - Implement readiness and liveness probes
   - Use meaningful health check endpoints

3. **Security**
   - Use security contexts
   - Implement network policies
   - Regularly scan images

### Monitoring Best Practices

1. **SLOs and SLIs**
   - Define meaningful SLOs
   - Implement appropriate alerting
   - Regular SLO review

2. **Dashboard Design**
   - Focus on actionable metrics
   - Use appropriate visualizations
   - Regular dashboard review

### CI/CD Best Practices

1. **Pipeline Design**
   - Fast feedback loops
   - Automated testing
   - Security scanning

2. **Deployment Strategies**
   - Use progressive delivery
   - Implement rollback mechanisms
   - Monitor deployments

## üìû Support

For issues and questions:
- Open a GitHub issue
- Contact the DevOps team
- Check the troubleshooting section

## üìß Contact

For direct inquiries, please contact:
- Email: techlekedev@gmail.com
- GitHub: [leketech](https://github.com/leketech)

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](../LICENSE) file for details.